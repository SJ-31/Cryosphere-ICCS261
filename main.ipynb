{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from qiime2 import Metadata\n",
    "import pandas as pd\n",
    "from qiime2 import Artifact, sdk\n",
    "from qiime2.plugins.dada2.methods import denoise_pyro # The samples were obtained through pyrosequencing\n",
    "import qiime2.plugins.metadata.actions as metadata_actions\n",
    "from qiime2.plugins.feature_classifier.pipelines import classify_consensus_blast\n",
    "import qiime2.plugins.feature_table.methods as ftm\n",
    "import qiime2.plugins.feature_classifier.actions as feature_classifier_actions\n",
    "from qiime2.plugins.feature_table.visualizers import tabulate_seqs\n",
    "import qiime2.plugins.feature_table.actions as fta\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib \n",
    "import seaborn as sns\n",
    "from Bio import SeqIO\n",
    "%matplotlib inline\n",
    "\n",
    "matplotlib.use('module://ipykernel.pylab.backend_inline')\n",
    "pm = sdk.PluginManager()\n",
    "def see(artifact):\n",
    "    from_format = artifact.format\n",
    "    if issubclass(from_format, sdk.plugin_manager.SingleFileDirectoryFormatBase):\n",
    "        from_format = artifact.format.file.format\n",
    "    return set(pm.transformers[from_format].keys())\n",
    "import os\n",
    "import pandas\n",
    "import qiime2\n",
    "import tempfile\n",
    "\n",
    "def v2frame(viz_fp: str) -> list:\n",
    "    '''viz_fp is a path to the qiime2 visualization object'''\n",
    "    viz = qiime2.Visualization.load(viz_fp)\n",
    "    with tempfile.TemporaryDirectory() as tmpdir:\n",
    "        viz.export_data(tmpdir)\n",
    "        fp = os.path.join(tmpdir, 'quality-plot.html')\n",
    "        ov = os.path.join(tmpdir, 'overview.html')\n",
    "        dfs = pandas.read_html(fp, index_col=0)\n",
    "        df2s = pandas.read_html(ov, index_col=0)\n",
    "    return dfs + df2s"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing data from fastq\n",
    "Qiime2 uses a compressed type of file format called an 'Artifact' for its analyses. Artifacts have different semantic types e.g. `FeatureData[Sequence]`, `Phylogeny[Unrooted]` depending on the type of data they contain. To begin the analysis, I need to import my fastq files into `FeatureData[SequencesWithQuality]` or `FeatureData[PairedEndSequencesWithQuality]`. \n",
    "\n",
    "Although all of these reads were prepared with Illumina devices, sequencing quality can vary between sequencing centres, meaning that each sample will likely need specific parameters for cleaning. Furthermore, two of the samples were sequenced with paired-end format. This means that I'll need to import each sample into five different artifacts, merging them together once they have been cleaned\n",
    "\n",
    "Quality $(Q)$ is commonly measured in Phred scores, denoted as  $Q=-10 \\log_{10}P$, where $P$ is the probability of an incorrect base call. Therefore, higher values for Phred indicate a lower probability of an erroneous base. Every base position is given a Phred score, and it is common to see the score decrease the longer the read \n",
    "\n",
    "```bash\n",
    "# Relevant commands\n",
    "qiime tools import \\\n",
    "  --type 'SampleData[PairedEndSequencesWithQuality]' \\\n",
    "  --input-path devon.tsv \\\n",
    "  --output-path devonFQ.qza \\\n",
    "  --input-format PairedEndFastqManifestPhred64V2\n",
    "\n",
    "qiime tools import \\\n",
    "  --type 'SampleData[SequencesWithQuality]' \\\n",
    "  --input-path neem.tsv \\\n",
    "  --output-path neem.qza \\\n",
    "  --input-format SingleEndFastqManifestPhred33V2\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial exploration\n",
    "To get an idea of each sample's read quality, I used external tools: `FastQC` paired with `MultiQC`. I was mainly looking for the \n",
    "\n",
    "```bash\n",
    "for sample in {Barrow_Alaska,Devon_ice_cap,Mutzagh_Ata,Greenland_ice_sheet,Neem}\n",
    "    do \n",
    "        fastqc ${sample}/*\n",
    "        multiqc $sample -f\n",
    "    done\n",
    "```\n",
    "\n",
    "For j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Position (bp)</th>\n",
       "      <th>SRR21738726</th>\n",
       "      <th>SRR21738727</th>\n",
       "      <th>SRR21738728</th>\n",
       "      <th>SRR21738729</th>\n",
       "      <th>SRR21738730</th>\n",
       "      <th>SRR21738731</th>\n",
       "      <th>SRR21738732</th>\n",
       "      <th>SRR21738733</th>\n",
       "      <th>SRR21738734</th>\n",
       "      <th>...</th>\n",
       "      <th>SRR21738774</th>\n",
       "      <th>SRR21738775</th>\n",
       "      <th>SRR21738776</th>\n",
       "      <th>SRR21738777</th>\n",
       "      <th>SRR21738778</th>\n",
       "      <th>SRR21738779</th>\n",
       "      <th>SRR21738780</th>\n",
       "      <th>SRR21738781</th>\n",
       "      <th>SRR21738782</th>\n",
       "      <th>SRR21738783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>32.556464</td>\n",
       "      <td>32.513028</td>\n",
       "      <td>32.618960</td>\n",
       "      <td>31.952148</td>\n",
       "      <td>36.769341</td>\n",
       "      <td>36.181801</td>\n",
       "      <td>32.457361</td>\n",
       "      <td>32.998586</td>\n",
       "      <td>36.282621</td>\n",
       "      <td>...</td>\n",
       "      <td>32.423528</td>\n",
       "      <td>32.437997</td>\n",
       "      <td>32.109506</td>\n",
       "      <td>32.723858</td>\n",
       "      <td>32.669556</td>\n",
       "      <td>32.620296</td>\n",
       "      <td>32.309986</td>\n",
       "      <td>32.436535</td>\n",
       "      <td>32.098632</td>\n",
       "      <td>32.421804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>32.340534</td>\n",
       "      <td>32.055915</td>\n",
       "      <td>32.912858</td>\n",
       "      <td>32.703985</td>\n",
       "      <td>36.574296</td>\n",
       "      <td>36.464845</td>\n",
       "      <td>32.386089</td>\n",
       "      <td>32.392373</td>\n",
       "      <td>36.549014</td>\n",
       "      <td>...</td>\n",
       "      <td>32.836605</td>\n",
       "      <td>32.677679</td>\n",
       "      <td>32.484029</td>\n",
       "      <td>32.364465</td>\n",
       "      <td>32.436932</td>\n",
       "      <td>32.252363</td>\n",
       "      <td>32.818052</td>\n",
       "      <td>32.644565</td>\n",
       "      <td>32.375321</td>\n",
       "      <td>32.704913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>32.676928</td>\n",
       "      <td>33.006785</td>\n",
       "      <td>32.420093</td>\n",
       "      <td>32.085292</td>\n",
       "      <td>36.115464</td>\n",
       "      <td>36.451733</td>\n",
       "      <td>32.810785</td>\n",
       "      <td>32.784026</td>\n",
       "      <td>36.446220</td>\n",
       "      <td>...</td>\n",
       "      <td>32.417235</td>\n",
       "      <td>32.868715</td>\n",
       "      <td>32.236824</td>\n",
       "      <td>32.793034</td>\n",
       "      <td>32.669621</td>\n",
       "      <td>33.047794</td>\n",
       "      <td>32.324027</td>\n",
       "      <td>32.850439</td>\n",
       "      <td>32.131472</td>\n",
       "      <td>32.572303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>32.943249</td>\n",
       "      <td>32.493961</td>\n",
       "      <td>32.458894</td>\n",
       "      <td>32.749672</td>\n",
       "      <td>37.070779</td>\n",
       "      <td>36.970764</td>\n",
       "      <td>33.026628</td>\n",
       "      <td>32.944820</td>\n",
       "      <td>37.089327</td>\n",
       "      <td>...</td>\n",
       "      <td>32.638480</td>\n",
       "      <td>32.946150</td>\n",
       "      <td>32.531195</td>\n",
       "      <td>32.990324</td>\n",
       "      <td>32.833054</td>\n",
       "      <td>33.038921</td>\n",
       "      <td>32.603378</td>\n",
       "      <td>32.734268</td>\n",
       "      <td>32.767295</td>\n",
       "      <td>32.650283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>33.127655</td>\n",
       "      <td>33.139903</td>\n",
       "      <td>32.874607</td>\n",
       "      <td>32.308082</td>\n",
       "      <td>36.836939</td>\n",
       "      <td>35.804727</td>\n",
       "      <td>33.201336</td>\n",
       "      <td>33.289707</td>\n",
       "      <td>35.886218</td>\n",
       "      <td>...</td>\n",
       "      <td>32.981249</td>\n",
       "      <td>32.919145</td>\n",
       "      <td>32.864025</td>\n",
       "      <td>33.025866</td>\n",
       "      <td>33.240044</td>\n",
       "      <td>33.101581</td>\n",
       "      <td>33.014091</td>\n",
       "      <td>33.067972</td>\n",
       "      <td>32.932185</td>\n",
       "      <td>33.045927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>451</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>454</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>464</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>474</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>480</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Position (bp)  SRR21738726  SRR21738727  SRR21738728  SRR21738729  \\\n",
       "0                1    32.556464    32.513028    32.618960    31.952148   \n",
       "1                2    32.340534    32.055915    32.912858    32.703985   \n",
       "2                3    32.676928    33.006785    32.420093    32.085292   \n",
       "3                4    32.943249    32.493961    32.458894    32.749672   \n",
       "4                5    33.127655    33.139903    32.874607    32.308082   \n",
       "..             ...          ...          ...          ...          ...   \n",
       "145            451          NaN          NaN          NaN          NaN   \n",
       "146            454          NaN          NaN          NaN          NaN   \n",
       "147            464          NaN          NaN          NaN          NaN   \n",
       "148            474          NaN          NaN          NaN          NaN   \n",
       "149            480          NaN          NaN          NaN          NaN   \n",
       "\n",
       "     SRR21738730  SRR21738731  SRR21738732  SRR21738733  SRR21738734  ...  \\\n",
       "0      36.769341    36.181801    32.457361    32.998586    36.282621  ...   \n",
       "1      36.574296    36.464845    32.386089    32.392373    36.549014  ...   \n",
       "2      36.115464    36.451733    32.810785    32.784026    36.446220  ...   \n",
       "3      37.070779    36.970764    33.026628    32.944820    37.089327  ...   \n",
       "4      36.836939    35.804727    33.201336    33.289707    35.886218  ...   \n",
       "..           ...          ...          ...          ...          ...  ...   \n",
       "145          NaN          NaN          NaN          NaN          NaN  ...   \n",
       "146          NaN          NaN          NaN          NaN          NaN  ...   \n",
       "147          NaN          NaN          NaN          NaN          NaN  ...   \n",
       "148          NaN          NaN          NaN          NaN          NaN  ...   \n",
       "149          NaN          NaN          NaN          NaN          NaN  ...   \n",
       "\n",
       "     SRR21738774  SRR21738775  SRR21738776  SRR21738777  SRR21738778  \\\n",
       "0      32.423528    32.437997    32.109506    32.723858    32.669556   \n",
       "1      32.836605    32.677679    32.484029    32.364465    32.436932   \n",
       "2      32.417235    32.868715    32.236824    32.793034    32.669621   \n",
       "3      32.638480    32.946150    32.531195    32.990324    32.833054   \n",
       "4      32.981249    32.919145    32.864025    33.025866    33.240044   \n",
       "..           ...          ...          ...          ...          ...   \n",
       "145          NaN          NaN          NaN          NaN          NaN   \n",
       "146          NaN          NaN          NaN          NaN          NaN   \n",
       "147          NaN          NaN          NaN          NaN          NaN   \n",
       "148          NaN          NaN          NaN          NaN          NaN   \n",
       "149          NaN          NaN          NaN          NaN          NaN   \n",
       "\n",
       "     SRR21738779  SRR21738780  SRR21738781  SRR21738782  SRR21738783  \n",
       "0      32.620296    32.309986    32.436535    32.098632    32.421804  \n",
       "1      32.252363    32.818052    32.644565    32.375321    32.704913  \n",
       "2      33.047794    32.324027    32.850439    32.131472    32.572303  \n",
       "3      33.038921    32.603378    32.734268    32.767295    32.650283  \n",
       "4      33.101581    33.014091    33.067972    32.932185    33.045927  \n",
       "..           ...          ...          ...          ...          ...  \n",
       "145    34.000000          NaN          NaN          NaN          NaN  \n",
       "146          NaN          NaN          NaN          NaN          NaN  \n",
       "147          NaN          NaN          NaN          NaN          NaN  \n",
       "148          NaN          NaN          NaN          NaN          NaN  \n",
       "149          NaN          NaN          NaN          NaN          NaN  \n",
       "\n",
       "[150 rows x 59 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quality = pd.read_csv('data/fastqc_per_base_sequence_quality_plot.tsv', sep='\\t')\n",
    "# fig, ax = plt.subplots()\n",
    "# for i in quality.columns:\n",
    "#     ax.scatter(x = quality.index, y = quality[i])\n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning\n",
    "- Ordinarily, we clean fastq data by trimming the reads to a length with relatively high quality scores (e.g. the average quality at base 200+ is less than 30, so we trim to keep only the first 200 bases from the 5' end). Unfortunately, several of the samples in each site exhibit varying mean quality scores at the same base position. In addition to using a read trimmer, `dada2`, I will process the reads with a quality filter to retain high-confidence hits. An adapter filter will also be used because of the adapter content in some samples.  \n",
    "- The read lengths I've trimmed to are listed in the `samplelist.tsv` file, along with the sample names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the artifacts\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence clustering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taxonomic analyses\n",
    "For sample taxonomic classification, I will be trying out all three of the methods available in qiime2: "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Database preparation\n",
    "Two databases were obtained:\n",
    "\n",
    "- All annotated 16S rRNA from the NCBI ftp [website](https://ftp-ncbi-nlm-nih-gov.ejournal.mahidol.ac.th/blast/db/v5/)\n",
    "- Annotated 16S rRNA used by the tool [MicFunPred](https://github.com/microDM/MicFunPred)\n",
    "- A 16S rRNA database from [EzBioCloud](https://www.ezbiocloud.net/dashboard)\n",
    "\n",
    "The MicFunPred and NCBI databases were obtained in the standard BLAST format, and need to be converted into compatible data types for import into the qiime2 workflow. Specficially, I needed to convert them into FASTA format with an associated taxonomy mapping file (in HeaderlessTSVTaxonomyFormat)\n",
    "- Steps\n",
    "    - 1 Extract all entries from the database in FASTA format\n",
    "    - 2 Extract the header and convert it into the HeaderLessTSVTaxonomyFormat, which is a tab-delimited file of FASTA identifiers followed by their taxonomic assignments\n",
    "    - 3 Remove the taxonomic assignments from the original FASTA file\n",
    "    - 4 Concatenate the respective files types together, then import them files as qiime2 Artifacts\n",
    "    - 5 Repeat for the other database (if both databases used the identifier conventions I could have combined them and processed them together but unfortunately this was not the case )\n",
    "\n",
    "```bash\n",
    "# 1\n",
    "blastdbcmd -db NCBI_16S/16S_ribosomal_RNA -entry all > NCBI_16S.fasta\n",
    "blastdbcmd -db micfun/micfun16S -entry all > micfun.fasta\n",
    "\n",
    "# 2 \n",
    "grep '>' NCBI_16S.fasta | tr -d '>' | sed 's/ /\\t/' | sed 's/ /_/g' > NCBI_16SID.txt\n",
    "grep '>' micfun.fasta | tr -d '>' | sed 's/_/\\t/' | sort | uniq > micfunID.txt # Unfortunately several of the headers repeat \n",
    "\n",
    "# 3 \n",
    "cat micfun.fasta | sed 's/_.*//' > micfunID.fasta\n",
    "cat NCBI_16S.fasta | sed 's/ .*//' > ncbi16sID.fasta\n",
    "\n",
    "# 4 \n",
    "cat micfunID.txt NCBI_16SID.txt EzBioCloud/ezbiocloud_id_taxonomy.txt > all_mappings.txt\n",
    "cat EzBioCloud/ezbiocloud_qiime_full.fasta ncbi16sID.fasta micfun.fasta > all.fasta\n",
    "qiime tools import     --type FeatureData[Taxonomy]     --input-format HeaderlessTSVTaxonomyFormat     --input-path all.fasta     --output-path all_fasta.qza\n",
    "qiime tools import     --type FeatureData[Taxonomy]     --input-format HeaderlessTSVTaxonomyFormat     --input-path all_uniqIDs.txt     --output-path Ids.qza\n",
    "```\n",
    "\n",
    "- Altogether, the database contains 130,122 sequences (though there might be some repetition that was overlooked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script for removing redundant ids\n",
    "from Bio import SeqIO\n",
    "import csv\n",
    "\n",
    "exists: set = set()\n",
    "mapped = open('all_uniq.fasta', 'w+')\n",
    "for seq in SeqIO.parse('all.fasta', 'fasta'):\n",
    "    if seq.id in exists:\n",
    "        continue\n",
    "    exists.add(seq.id)\n",
    "    mapped.write(f'>{seq.id}\\n')\n",
    "    mapped.write(f'{seq.seq}\\n')\n",
    "mapped.close\n",
    "\n",
    "uniq = open('all_uniqIDs.txt', 'w+')\n",
    "exists2: set = set()\n",
    "with open('all_mappings.txt', 'r') as i:\n",
    "    for id in csv.reader(i, delimiter='\\t'):\n",
    "        if id[0] in exists2:\n",
    "            continue\n",
    "        exists2.add(id[0])\n",
    "        uniq.write(f'{id[0]}\\t{id[1]}\\n')\n",
    "uniq.close\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging with other data\n",
    "The qiime2 website provides links for data resources, including 16s rRNA reference sequences. These are from the SILVA and greengenes databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sc31/Bio_SDD/miniconda3/envs/qiime2-2023.2/lib/python3.8/site-packages/q2_types/feature_data/_transformer.py:258: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for id_, seq in data.iteritems():\n"
     ]
    }
   ],
   "source": [
    "# Import database artifacts\n",
    "IDs = Artifact.load('data/artifacts/Ids.qza') \n",
    "RefSeqs = Artifact.load('data/artifacts/all_fasta.qza')\n",
    "silvaSeqs = Artifact.load('data/downloads/silva-138-99-seqs.qza')\n",
    "silvaIDs = Artifact.load('data/downloads/silva-138-99-tax.qza')\n",
    "greenSeqs = Artifact.load('data/downloads/2022.10.backbone.full-length.fna.qza')\n",
    "greenIDs = Artifact.load('data/downloads/2022.10.backbone.tax.qza')\n",
    "AllIDs = ftm.merge_taxa([IDs, silvaIDs, greenIDs])\n",
    "AllSeqs = ftm.merge_seqs([RefSeqs, silvaSeqs, greenSeqs])\n",
    "AllIDs.merged_data.save('data/artifacts/AllIDs.qza')\n",
    "AllSeqs.merged_data.save('data/artifacts/AllSeqs.qza')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taxonomic classification\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diversity analyses"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load artifacts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qiime2-2023.2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
