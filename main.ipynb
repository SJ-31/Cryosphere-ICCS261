{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from qiime2 import Metadata\n",
    "import pandas as pd\n",
    "from qiime2 import Artifact, sdk\n",
    "from qiime2.plugins.dada2.methods import denoise_pyro # The samples were obtained through pyrosequencing\n",
    "import qiime2.plugins.metadata.actions as metadata_actions\n",
    "from qiime2.plugins.feature_classifier.pipelines import classify_consensus_blast\n",
    "import qiime2.plugins.feature_table.methods as ftm\n",
    "import qiime2.plugins.feature_classifier.actions as feature_classifier_actions\n",
    "from qiime2.plugins.feature_table.visualizers import tabulate_seqs\n",
    "import qiime2.plugins.feature_table.actions as fta\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib \n",
    "import seaborn as sns\n",
    "from Bio import SeqIO\n",
    "\n",
    "matplotlib.use('module://ipykernel.pylab.backend_inline')\n",
    "pm = sdk.PluginManager()\n",
    "def see(artifact):\n",
    "    from_format = artifact.format\n",
    "    if issubclass(from_format, sdk.plugin_manager.SingleFileDirectoryFormatBase):\n",
    "        from_format = artifact.format.file.format\n",
    "    return set(pm.transformers[from_format].keys())\n",
    "import os\n",
    "import pandas\n",
    "import qiime2\n",
    "import tempfile\n",
    "\n",
    "def v2frame(viz_fp: str) -> list:\n",
    "    '''viz_fp is a path to the qiime2 visualization object'''\n",
    "    viz = qiime2.Visualization.load(viz_fp)\n",
    "    with tempfile.TemporaryDirectory() as tmpdir:\n",
    "        viz.export_data(tmpdir)\n",
    "        fp = os.path.join(tmpdir, 'quality-plot.html')\n",
    "        ov = os.path.join(tmpdir, 'overview.html')\n",
    "        dfs = pandas.read_html(fp, index_col=0)\n",
    "        df2s = pandas.read_html(ov, index_col=0)\n",
    "    return dfs + df2s"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing data from fastq"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial exploration"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence clustering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taxonomic analyses\n",
    "For sample taxonomic classification, I will be trying out all three of the methods available in qiime2: "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Database preparation\n",
    "Two databases were obtained:\n",
    "\n",
    "- All annotated 16S rRNA from the NCBI ftp [website](https://ftp-ncbi-nlm-nih-gov.ejournal.mahidol.ac.th/blast/db/v5/)\n",
    "- Annotated 16S rRNA used by the tool [MicFunPred](https://github.com/microDM/MicFunPred)\n",
    "- A 16S rRNA database from [EzBioCloud](https://www.ezbiocloud.net/dashboard)\n",
    "\n",
    "The MicFunPred and NCBI databases were obtained in the standard BLAST format, and need to be converted into compatible data types for import into the qiime2 workflow. Specficially, I needed to convert them into FASTA format with an associated taxonomy mapping file (in HeaderlessTSVTaxonomyFormat)\n",
    "- Steps\n",
    "    - 1 Extract all entries from the database in FASTA format\n",
    "    - 2 Extract the header and convert it into the HeaderLessTSVTaxonomyFormat, which is a tab-delimited file of FASTA identifiers followed by their taxonomic assignments\n",
    "    - 3 Remove the taxonomic assignments from the original FASTA file\n",
    "    - 4 Concatenate the respective files types together, then import them files as qiime2 Artifacts\n",
    "    - 5 Repeat for the other database (if both databases used the identifier conventions I could have combined them and processed them together but unfortunately this was not the case )\n",
    "\n",
    "```bash\n",
    "# 1\n",
    "blastdbcmd -db NCBI_16S/16S_ribosomal_RNA -entry all > NCBI_16S.fasta\n",
    "blastdbcmd -db micfun/micfun16S -entry all > micfun.fasta\n",
    "\n",
    "# 2 \n",
    "grep '>' NCBI_16S.fasta | tr -d '>' | sed 's/ /\\t/' | sed 's/ /_/g' > NCBI_16SID.txt\n",
    "grep '>' micfun.fasta | tr -d '>' | sed 's/_/\\t/' | sort | uniq > micfunID.txt # Unfortunately several of the headers repeat \n",
    "\n",
    "# 3 \n",
    "cat micfun.fasta | sed 's/_.*//' > micfunID.fasta\n",
    "cat NCBI_16S.fasta | sed 's/ .*//' > ncbi16sID.fasta\n",
    "\n",
    "# 4 \n",
    "cat micfunID.txt NCBI_16SID.txt EzBioCloud/ezbiocloud_id_taxonomy.txt > all_mappings.txt\n",
    "cat EzBioCloud/ezbiocloud_qiime_full.fasta ncbi16sID.fasta micfun.fasta > all.fasta\n",
    "qiime tools import     --type FeatureData[Taxonomy]     --input-format HeaderlessTSVTaxonomyFormat     --input-path all.fasta     --output-path all_fasta.qza\n",
    "qiime tools import     --type FeatureData[Taxonomy]     --input-format HeaderlessTSVTaxonomyFormat     --input-path all_uniqIDs.txt     --output-path Ids.qza\n",
    "```\n",
    "\n",
    "- Altogether, the database contains 130,122 sequences (though there might be some repetition that was overlooked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script for removing redundant ids\n",
    "from Bio import SeqIO\n",
    "import csv\n",
    "\n",
    "exists: set = set()\n",
    "mapped = open('all_uniq.fasta', 'w+')\n",
    "for seq in SeqIO.parse('all.fasta', 'fasta'):\n",
    "    if seq.id in exists:\n",
    "        continue\n",
    "    exists.add(seq.id)\n",
    "    mapped.write(f'>{seq.id}\\n')\n",
    "    mapped.write(f'{seq.seq}\\n')\n",
    "mapped.close\n",
    "\n",
    "uniq = open('all_uniqIDs.txt', 'w+')\n",
    "exists2: set = set()\n",
    "with open('all_mappings.txt', 'r') as i:\n",
    "    for id in csv.reader(i, delimiter='\\t'):\n",
    "        if id[0] in exists2:\n",
    "            continue\n",
    "        exists2.add(id[0])\n",
    "        uniq.write(f'{id[0]}\\t{id[1]}\\n')\n",
    "uniq.close\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging with other data\n",
    "The qiime2 website provides links for data resources, including 16s rRNA reference sequences. These are from the SILVA and greengenes databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sc31/Bio_SDD/miniconda3/envs/qiime2-2023.2/lib/python3.8/site-packages/q2_types/feature_data/_transformer.py:258: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for id_, seq in data.iteritems():\n"
     ]
    }
   ],
   "source": [
    "# Import database artifacts\n",
    "IDs = Artifact.load('data/artifacts/Ids.qza') \n",
    "RefSeqs = Artifact.load('data/artifacts/all_fasta.qza')\n",
    "silvaSeqs = Artifact.load('data/downloads/silva-138-99-seqs.qza')\n",
    "silvaIDs = Artifact.load('data/downloads/silva-138-99-tax.qza')\n",
    "greenSeqs = Artifact.load('data/downloads/2022.10.backbone.full-length.fna.qza')\n",
    "greenIDs = Artifact.load('data/downloads/2022.10.backbone.tax.qza')\n",
    "AllIDs = ftm.merge_taxa([IDs, silvaIDs, greenIDs])\n",
    "AllSeqs = ftm.merge_seqs([RefSeqs, silvaSeqs, greenSeqs])\n",
    "AllIDs.merged_data.save('data/artifacts/AllIDs.qza')\n",
    "AllSeqs.merged_data.save('data/artifacts/AllSeqs.qza')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taxonomic classification\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diversity analyses"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AllIDs = Artifact.load('data/artifacts/AllIDs.qza')\n",
    "AllSeqs = Artifact.load('data/artifacts/AllSeqs.qza')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qiime2-2023.2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
